# ğŸ§  NeuroConscious Transformer (NCT)

[![PyPI](https://img.shields.io/pypi/v/neuroconscious-transformer?style=for-the-badge&logo=pypi&logoColor=white)](https://pypi.org/project/neuroconscious-transformer/)
[![Python](https://img.shields.io/pypi/pyversions/neuroconscious-transformer?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](LICENSE)

**Version**: v3.1.3 | **ç‰ˆæœ¬**: v3.1.3  
**Author**: WENG YONGGANG(ç¿å‹‡åˆš) | **é‚®ç®±**: wyg5208@126.com  

---

## ğŸ“¦ Installation / å®‰è£…

### Basic Installation / åŸºç¡€å®‰è£…

```bash
pip install neuroconscious-transformer
```

### Complete Installation (with Dashboard) / å®Œæ•´å®‰è£…ï¼ˆå«å¯è§†åŒ–å·¥å…·ï¼‰

```bash
pip install neuroconscious-transformer[dashboard]
```

### Verify Installation / éªŒè¯å®‰è£…

```bash
python -c "from nct_modules import NCTManager; print('âœ“ Installation successful')"
```

### Requirements / ä¾èµ–è¦æ±‚

- Python 3.9+
- PyTorch 2.0+
- NumPy 1.24+
- SciPy 1.10+

---

## ğŸš€ Quick Start / å¿«é€Ÿå¼€å§‹

### Example 1: Basic Usage / åŸºç¡€ä½¿ç”¨

```python
from nct_modules import NCTManager, NCTConfig
import numpy as np

# Create configuration / åˆ›å»ºé…ç½®
config = NCTConfig(
    n_heads=8,           # Number of attention heads / æ³¨æ„åŠ›å¤´æ•°
    n_layers=4,          # Number of Transformer layers / Transformer å±‚æ•°
    d_model=768,         # Representation dimension / è¡¨å¾ç»´åº¦
    gamma_freq=40.0,     # Gamma wave frequency (Hz) / Î³æ³¢é¢‘ç‡
)

# Initialize manager / åˆå§‹åŒ–ç®¡ç†å™¨
manager = NCTManager(config)
manager.start()

# Process consciousness cycles / å¤„ç†æ„è¯†å‘¨æœŸ
for cycle in range(10):
    # Prepare sensory input / å‡†å¤‡æ„Ÿè§‰è¾“å…¥
    sensory_data = {
        'visual': np.random.randn(28, 28).astype(np.float32),
        'auditory': np.random.randn(10, 10).astype(np.float32),
        'interoceptive': np.random.randn(10).astype(np.float32),
    }
    
    # Process cycle / å¤„ç†å‘¨æœŸ
    state = manager.process_cycle(sensory_data)
    
    # View results / æŸ¥çœ‹ç»“æœ
    print(f"Cycle {cycle + 1}:")
    print(f"  Î¦ Value (Integrated Information): {state.consciousness_metrics.get('phi_value', 0):.3f}")
    print(f"  Free Energy (Prediction Error): {state.self_representation['free_energy']:.4f}")

# Stop / åœæ­¢
manager.stop()
```

### Example 2: Multimodal Encoding / å¤šæ¨¡æ€ç¼–ç 

```python
from nct_modules import MultiModalEncoder
import torch

encoder = MultiModalEncoder(
    visual_embed_dim=256,
    audio_embed_dim=256,
    intero_embed_dim=256,
)

# Prepare inputs / å‡†å¤‡è¾“å…¥
visual_input = torch.randn(1, 3, 28, 28)  # RGB image / RGB å›¾åƒ
audio_input = torch.randn(1, 10, 10)       # Audio spectrogram / éŸ³é¢‘é¢‘è°±
intero_input = torch.randn(1, 10)          # Interoceptive signals / å†…æ„Ÿå—ä¿¡å·

sensory_tensors = {
    'visual': visual_input,
    'auditory': audio_input,
    'interoceptive': intero_input,
}

# Encode / ç¼–ç 
embeddings = encoder(sensory_tensors)
print(f"Visual embedding shape: {embeddings['visual'].shape}")  # [1, 768]
```

### Example 3: Î¦ Value Computation / Î¦å€¼è®¡ç®—

```python
from nct_modules import PhiFromAttention
import torch

phi_calc = PhiFromAttention()

# Simulate attention maps / æ¨¡æ‹Ÿæ³¨æ„åŠ›å›¾
attention_maps = torch.rand(8, 768, 768)  # [heads, seq_len, seq_len]

# Compute Î¦ value / è®¡ç®— Î¦å€¼
phi_value = phi_calc.compute_phi(attention_maps)
print(f"Integrated Information Î¦: {phi_value:.3f}")
print(f"Consciousness level: {'High' if phi_value > 0.5 else 'Medium' if phi_value > 0.2 else 'Low'}")
```

### Example 4: Transformer-STDP Hybrid Learning / æ··åˆå­¦ä¹ 

```python
from nct_modules import TransformerSTDP, STDPEvent
import torch

stdp_learner = TransformerSTDP(n_neurons=768, d_model=768)

# Create STDP event / åˆ›å»º STDP äº‹ä»¶
event = STDPEvent(
    pre_idx=10,      # Pre-synaptic neuron index / çªè§¦å‰ç¥ç»å…ƒç´¢å¼•
    post_idx=20,     # Post-synaptic neuron index / çªè§¦åç¥ç»å…ƒç´¢å¼•
    delta_t=0.015,   # Time difference (seconds) / æ—¶é—´å·®
)

# Update synapse / æ›´æ–°çªè§¦
synaptic_update = stdp_learner.update(event)
print(f"Synaptic strength change: Î”w = {synaptic_update.delta_w:.6f}")
```

### Example 5: Complete Experiment / å®Œæ•´å®éªŒ

```python
"""
NCT Consciousness Computation Experiment
å±•ç¤ºï¼šMultimodal Fusion + Î¦ Monitoring + STDP Learning
"""
from nct_modules import NCTManager, NCTConfig
import numpy as np
import matplotlib.pyplot as plt

# Configuration / é…ç½®
config = NCTConfig(
    n_heads=8,
    n_layers=4,
    d_model=768,
    stdp_learning_rate=0.01,
)

manager = NCTManager(config)
manager.start()

# Record data / è®°å½•æ•°æ®
phi_values = []
free_energies = []

# Run 100 cycles / è¿è¡Œ 100 ä¸ªå‘¨æœŸ
for cycle in range(100):
    # Generate meaningful sensory input (with patterns) / ç”Ÿæˆæœ‰æ„ä¹‰çš„æ„Ÿè§‰è¾“å…¥
    visual = np.sin(np.linspace(0, cycle * 0.1, 28 * 28)).reshape(28, 28).astype(np.float32)
    audio = np.cos(np.linspace(0, cycle * 0.05, 10 * 10)).reshape(10, 10).astype(np.float32)
    intero = np.random.randn(10).astype(np.float32) * 0.5
    
    sensory_data = {
        'visual': visual,
        'auditory': audio,
        'interoceptive': intero,
    }
    
    # Process / å¤„ç†
    state = manager.process_cycle(sensory_data)
    
    # Record / è®°å½•
    phi_values.append(state.consciousness_metrics.get('phi_value', 0))
    free_energies.append(state.self_representation['free_energy'])
    
    # Print every 10 cycles / æ¯ 10 ä¸ªå‘¨æœŸæ‰“å°
    if (cycle + 1) % 10 == 0:
        print(f"Cycle {cycle + 1}/100 | Î¦={phi_values[-1]:.3f} | FE={free_energies[-1]:.4f}")

manager.stop()

# Visualization / å¯è§†åŒ–
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(phi_values)
plt.title('Î¦ Value (Integrated Information)')
plt.xlabel('Cycle')
plt.ylabel('Î¦')
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.plot(free_energies)
plt.title('Free Energy (Prediction Error)')
plt.xlabel('Cycle')
plt.ylabel('FE')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('nct_experiment_results.png', dpi=300)
plt.show()

print("\nâœ… Experiment complete! Results saved to nct_experiment_results.png")
```

---

## ğŸ”§ Core API Reference / æ ¸å¿ƒ API é€ŸæŸ¥

### NCTConfig - Configuration Class / é…ç½®ç±»

```python
from nct_modules import NCTConfig

config = NCTConfig(
    # Core parameters / æ ¸å¿ƒå‚æ•°
    n_heads=8,                    # Attention heads (workspace capacity) / æ³¨æ„åŠ›å¤´æ•°
    n_layers=4,                   # Transformer layers / Transformer å±‚æ•°
    d_model=768,                  # Representation dimension / è¡¨å¾ç»´åº¦
    dim_ff=3072,                  # Feed-forward network dimension / å‰é¦ˆç½‘ç»œç»´åº¦
    
    # Neuroscience parameters / ç¥ç»ç§‘å­¦å‚æ•°
    gamma_freq=40.0,              # Gamma wave frequency (Hz) / Î³æ³¢é¢‘ç‡
    stdp_learning_rate=0.01,      # STDP learning rate / STDP å­¦ä¹ ç‡
    attention_modulation_lambda=0.1,  # Attention modulation coefficient / æ³¨æ„åŠ›è°ƒåˆ¶ç³»æ•°
)
```

### NCTManager - Manager Class / ç®¡ç†å™¨ç±»

```python
from nct_modules import NCTManager

# Initialize / åˆå§‹åŒ–
manager = NCTManager(config)

# Start system / å¯åŠ¨ç³»ç»Ÿ
manager.start()

# Process one consciousness cycle / å¤„ç†ä¸€ä¸ªæ„è¯†å‘¨æœŸ
state = manager.process_cycle(sensory_data)

# Stop system / åœæ­¢ç³»ç»Ÿ
manager.stop()

# Get statistics / è·å–ç»Ÿè®¡ä¿¡æ¯
stats = manager.get_stats()

# Save model / ä¿å­˜æ¨¡å‹
torch.save(manager.state_dict(), 'model.pth')

# Load model / åŠ è½½æ¨¡å‹
manager.load_state_dict(torch.load('model.pth'))
```

### ConsciousnessState - State Object / çŠ¶æ€å¯¹è±¡

```python
# Access consciousness metrics / è®¿é—®æ„è¯†åº¦é‡
state.awareness_level              # Consciousness level (low/moderate/high) / æ„è¯†æ°´å¹³
state.consciousness_metrics        # Metrics dictionary (includes Î¦ value) / æ„è¯†åº¦é‡å­—å…¸
state.self_representation          # Self-representation (free energy, confidence) / è‡ªæˆ‘è¡¨å¾
state.workspace_content            # Global workspace content / å…¨å±€å·¥ä½œç©ºé—´å†…å®¹

# Example usage / ç¤ºä¾‹ç”¨æ³•
print(f"Consciousness level: {state.awareness_level}")
print(f"Î¦ value: {state.consciousness_metrics['phi_value']:.3f}")
print(f"Free energy: {state.self_representation['free_energy']:.4f}")
```

### Other Core Components / å…¶ä»–æ ¸å¿ƒç»„ä»¶

#### MultiModalEncoder / å¤šæ¨¡æ€ç¼–ç å™¨
```python
from nct_modules import MultiModalEncoder

encoder = MultiModalEncoder(
    visual_embed_dim=256,
    audio_embed_dim=256,
    intero_embed_dim=256,
)

embeddings = encoder(sensory_tensors)
```

#### PhiFromAttention / Î¦å€¼è®¡ç®—å™¨
```python
from nct_modules import PhiFromAttention

phi_calc = PhiFromAttention()
phi_value = phi_calc.compute_phi(attention_maps)
```

#### TransformerSTDP / æ··åˆå­¦ä¹ 
```python
from nct_modules import TransformerSTDP, STDPEvent

stdp = TransformerSTDP(n_neurons=768, d_model=768)
event = STDPEvent(pre_idx=10, post_idx=20, delta_t=0.015)
update = stdp.update(event)
```

#### NCTWorkspace / å…¨å±€å·¥ä½œç©ºé—´
```python
from nct_modules import NCTWorkspace

workspace = NCTWorkspace(n_heads=8, d_model=768)
global_content = workspace(attention_maps, query)
```

---

## ğŸ¨ Advanced Features / é«˜çº§åŠŸèƒ½

### GPU Acceleration / GPU åŠ é€Ÿ

```python
import torch
torch.set_default_device('cuda')  # Automatically use GPU / è‡ªåŠ¨ä½¿ç”¨ GPU

# All computations will now run on GPU / æ‰€æœ‰è®¡ç®—å°†åœ¨ GPU ä¸Šè¿è¡Œ
config = NCTConfig()
manager = NCTManager(config)
```

### Custom Sensory Inputs / è‡ªå®šä¹‰æ„Ÿè§‰è¾“å…¥

```python
# Supports arbitrary shapes (automatically adapts) / æ”¯æŒä»»æ„å½¢çŠ¶ï¼ˆè‡ªåŠ¨é€‚é…ï¼‰
sensory_data = {
    'visual': your_image,           # [H, W] or [C, H, W]
    'auditory': your_audio,         # [T, F]
    'interoceptive': your_signals,  # [N]
}
```

### Model Checkpointing / æ¨¡å‹æ£€æŸ¥ç‚¹

```python
import torch
from nct_modules import NCTManager, NCTConfig

# Save checkpoint / ä¿å­˜æ£€æŸ¥ç‚¹
checkpoint = {
    'config': config.to_dict(),
    'model_state': manager.state_dict(),
    'metrics': manager.get_stats(),
    'cycle': current_cycle,
}
torch.save(checkpoint, 'nct_checkpoint.pth')

# Load checkpoint / åŠ è½½æ£€æŸ¥ç‚¹
loaded = torch.load('nct_checkpoint.pth')
loaded_config = NCTConfig.from_dict(loaded['config'])
loaded_manager = NCTManager(loaded_config)
loaded_manager.load_state_dict(loaded['model_state'])

print(f"âœ“ Checkpoint loaded at cycle {loaded['cycle']}")
```

### Preset Configurations / é¢„è®¾é…ç½®

```python
# Large-scale configuration (research) / å¤§è§„æ¨¡é…ç½®ï¼ˆç ”ç©¶ç”¨ï¼‰
large_config = NCTConfig(
    n_heads=12,
    n_layers=6,
    d_model=1024,
    dim_ff=4096,
)

# Lightweight configuration (real-time) / è½»é‡çº§é…ç½®ï¼ˆå®æ—¶åº”ç”¨ï¼‰
small_config = NCTConfig(
    n_heads=4,
    n_layers=2,
    d_model=256,
    gamma_freq=30.0,
)

# Temporal learning configuration / æ—¶åºå…³è”å­¦ä¹ é…ç½®
temporal_config = NCTConfig(
    n_heads=8,
    n_layers=4,
    d_model=512,
    stdp_learning_rate=0.05,
    attention_modulation_lambda=0.2,
)
```

---

## ğŸ“Š Common Issues / å¸¸è§é—®é¢˜

### Q1: How to improve Î¦ value? / å¦‚ä½•æé«˜ Î¦å€¼ï¼Ÿ

- Increase `d_model` (representation dimension) / å¢åŠ  `d_model`ï¼ˆè¡¨å¾ç»´åº¦ï¼‰
- Increase `n_heads` (attention head count) / å¢åŠ  `n_heads`ï¼ˆæ³¨æ„åŠ›å¤´æ•°ï¼‰
- Use more meaningful sensory inputs (patterned data) / ä½¿ç”¨æ›´æœ‰æ„ä¹‰çš„æ„Ÿè§‰è¾“å…¥

### Q2: How to use custom modalities? / å¦‚ä½•ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ€ï¼Ÿ

```python
# Add any modality you want / æ·»åŠ ä»»æ„æ¨¡æ€
sensory_data = {
    'custom_modality_1': tensor1,
    'custom_modality_2': tensor2,
}

# The encoder will automatically adapt / ç¼–ç å™¨ä¼šè‡ªåŠ¨é€‚é…
```

### Q3: Dashboard not launching? / Dashboard æ— æ³•å¯åŠ¨ï¼Ÿ

```bash
# Install dashboard dependencies / å®‰è£… Dashboard ä¾èµ–
pip install neuroconscious-transformer[dashboard]

# Or manually install / æˆ–æ‰‹åŠ¨å®‰è£…
pip install streamlit plotly pandas

# Launch / å¯åŠ¨
nct-dashboard
```

---

## ğŸ“š Further Reading / å»¶ä¼¸é˜…è¯»

### Technical Blog Series / æŠ€æœ¯åšå®¢ç³»åˆ—

- [Consciousness: From Philosophy to Engineering](https://github.com/winclaw/NCT/tree/main/docs/csdn_blog/01_æ„è¯†çš„å¥¥ç§˜_ä»å“²å­¦æ€è¾¨åˆ°å·¥ç¨‹å®è·µ.md)
- [Attention as Global Workspace](https://github.com/winclaw/NCT/tree/main/docs/csdn_blog/02_Attention å¦‚ä½•æˆä¸ºå…¨å±€å·¥ä½œç©ºé—´_Miller å®šå¾‹çš„æ·±åº¦å­¦ä¹ è¯ é‡Š.md)
- [Transformer-STDP Integration](https://github.com/winclaw/NCT/tree/main/docs/csdn_blog/03_STDP+Transformer_å½“å±€éƒ¨å¯å¡‘æ€§é‡è§å…¨å±€è¯­ä¹‰.md)
- [Predictive Coding & Free Energy](https://github.com/winclaw/NCT/tree/main/docs/csdn_blog/04_é¢„æµ‹ç¼–ç =Decoder è®­ç»ƒ_Friston è‡ªç”±èƒ½çš„ Transformer å®ç°.md)

### Academic Paper / å­¦æœ¯è®ºæ–‡

- arXiv preprint: [NeuroConscious Transformer](https://arxiv.org/) (coming soon)
- Technical report with full experiments and ablation studies

### GitHub Repository / GitHub ä»“åº“

For source code, examples, and development documentation:  
https://github.com/winclaw/NCT

---

## ğŸ‘¨â€ğŸ’» Author & License / ä½œè€…ä¸è®¸å¯

**Author / ä½œè€…**: WENG YONGGANG (ç¿å‹‡åˆš)  
**Affiliation / æœºæ„**: Faculty of Computer Science and Information Technology, Universiti Teknologi Malaysia  
**Email / é‚®ç®±**: wyg5208@126.com  

**License / è®¸å¯è¯**: MIT License  

---

## ğŸ™ Acknowledgments / è‡´è°¢

This project integrates insights from:
- Transformer architecture (Vaswani et al., 2017)
- STDP mechanisms (Bi & Poo, 1998)
- Predictive Coding theory (Rao & Ballard, 1999)
- Integrated Information Theory (Tononi et al.)
- Global Workspace Theory (Baars, Dehaene)

æœ¬é¡¹ç›®èåˆäº†ä»¥ä¸‹ç†è®ºæ´è§ï¼š
- Transformer æ¶æ„ï¼ˆVaswani ç­‰ï¼Œ2017ï¼‰
- STDP æœºåˆ¶ï¼ˆBi & Poo, 1998ï¼‰
- é¢„æµ‹ç¼–ç ç†è®ºï¼ˆRao & Ballard, 1999ï¼‰
- æ•´åˆä¿¡æ¯è®ºï¼ˆTononi ç­‰ï¼‰
- å…¨å±€å·¥ä½œç©ºé—´ç†è®ºï¼ˆBaars, Dehaeneï¼‰

---

## ğŸ“¬ Contact / è”ç³»

- **GitHub Issues**: https://github.com/winclaw/NCT/issues
- **Email**: wyg5208@126.com
- **PyPI**: https://pypi.org/project/neuroconscious-transformer/

**Welcome to join the NeuroConscious community! ğŸ§ âœ¨**  
**æ¬¢è¿åŠ å…¥ NeuroConscious ç¤¾åŒºï¼ğŸ§ âœ¨**
